#!/usr/bin/env python3

import argparse as ap
from statistics import quantiles
from numpy import quantile
import polars as pl


def read_hmm(hmmfile, header_mark='#', eval=None):
    '''
    The function gets a tblout file generated by hmmsearch and retrieves all
    the information. Then, it returns a dictionary where the keys are the
    query protein accession and the values is a dictionary per hit containing
    all the information of the hit. The structure is:

    {Query: {subject_1: {hit_data}, subject_2: {hit_data}}}

    Args:
        hmmfile (str): path to the hmmsearch output file
        header_mark (str, optional): typographical mark to omit a line. Defaults to '#'.

    Returns:
        dict: dictionary containing all the queries, their hits and their information
    '''

    # Initialising the hits dictionary for the whole file
    hits = {}

    # Iterating through the hits
    for line in open(hmmfile, 'r'):
        # Checking whether the line contains the header mark
        if header_mark not in line:
            cols = [x for x in line.strip().split(" ") if x]
            # Joining the description
            if len(cols) > 18:
                cols[18] = ' '.join(cols[18:])
            
            # Initialising the hit data dictionary
            hit = {}
            
            # Adding data to the hit dictionary from the file
            hit['hit'] = cols[0]
            hit['id'] = cols[2]  # protein/ domain code
            hit['accession'] = cols[3]  # protein/ domain accession
            hit['evalue'] = float(cols[4])  # evalue (full sequence)
            hit['bitscore'] = float(cols[5])  # score (full sequence)
            hit['bias'] = float(cols[6])  # bias (full sequence)
            hit['domain_exp_num'] = float(cols[10])  # exp
            hit['region_num'] = int(cols[11])  # reg
            hit['cluster_num'] = int(cols[12])  # clu
            hit['overlap_num'] = int(cols[13])  # ov
            hit['env_num'] = int(cols[14])  # env
            hit['domain_obs_num'] = int(cols[15])  # dom
            hit['domain_reported_num'] = int(cols[16])  # rep
            hit['domain_included_num'] = int(cols[17])  # inc
            hit['description'] = cols[18]  # description of target
            hit['hsp_evalue'] = float(cols[7])  # evalue (best 1 domain)
            hit['hsp_bitscore'] = float(cols[8])  # score (best 1 domain)
            hit['hsp_bias'] = float(cols[9])  # bias (best 1 domain)

            if eval is not None:
                if hit['evalue'] <= eval:
                    # Checking whether the query is in the hits dictionary, if it is
                    # not, it is created
                    if hit['id'] not in hits.keys():
                        hits[hit['id']] = {}
                    # Appending the hit to the corresponding query and subject pair
                    hits[hit['id']][hit['hit']] = hit  # genome protein
            else:
                # Checking whether the query is in the hits dictionary, if it is
                # not, it is created
                if hit['hit'] not in hits.keys():
                    hits[hit['hit']] = {}
                # Appending the hit to the corresponding query and subject pair
                hits[hit['hit']][hit['id']] = hit  # genome protein

    return hits



def get_first_hit(hits):
    mineval = max([v['bitscore'] for k, v in hits.items()])
    first_hit = [v for k, v in hits.items() if v['bitscore'] == mineval][0]

    return first_hit



def main():
    parser = ap.ArgumentParser()
    parser.add_argument('-i', '--input', dest='input',
                        help='Input hmm tabular output.')
    parser.add_argument('-o', '--output', dest='output',
                        help='Output file in tsv format.')
    args = parser.parse_args()

    COGs_description = '/gpfs/projects/bsc40/current/mgil/dbs/profiles/NCBI_cogs_annotation.tsv'

    COGs = {}
    for i, line in enumerate(open(COGs_description, 'r')):
        if i > 0:
            COG_id, COG_category, description, rest = line.replace('\n', '').split('\t', 3)
            COGs[COG_id] = {'category': COG_category, 'description': description}

    hmm = read_hmm(args.input)

    odfl = []
    for i in hmm:
        first_hit = get_first_hit(hmm[i])
        bitscores = [x['bitscore'] for x in hmm[i].values()]
        threshold = quantile(bitscores, q=0.9)
        kept = [v['id'] for k, v in hmm[i].items() if v['id'] != first_hit['id'] and v['bitscore'] >= threshold]

        odfl.append({'protein': i,
                     'COG_fh': first_hit['id'],
                     'kept_COGs': ';'.join(kept),
                     'fh_category': COGs[first_hit['id']]['category'],
                     'fh_description': COGs[first_hit['id']]['description']})
    
    odf = pl.DataFrame(odfl)
    odf.write_csv(args.output, separator='\t')

    return 0


if __name__ == '__main__':
    main()